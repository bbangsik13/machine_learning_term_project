{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"colab":{"name":"quickstart_tutorial.ipynb의 사본","provenance":[{"file_id":"https://github.com/9bow/PyTorch-Tutorials-kr/blob/master/docs/_downloads/977d877f98ff2aef30969c3d4fa5702a/quickstart_tutorial.ipynb","timestamp":1637574787981}]}},"cells":[{"cell_type":"code","metadata":{"id":"EaBVgmZ3oAVx","executionInfo":{"status":"ok","timestamp":1637675420513,"user_tz":-540,"elapsed":267,"user":{"displayName":"빵식","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15051609577376359073"}}},"source":["%matplotlib inline"],"execution_count":218,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kppmj_BMoAVz"},"source":["\n","`파이토치(PyTorch) 기본 익히기 <intro.html>`_ ||\n","**빠른 시작** ||\n","`텐서(Tensor) <tensorqs_tutorial.html>`_ ||\n","`Dataset과 Dataloader <data_tutorial.html>`_ ||\n","`변형(Transform) <transforms_tutorial.html>`_ ||\n","`신경망 모델 구성하기 <buildmodel_tutorial.html>`_ ||\n","`Autograd <autogradqs_tutorial.html>`_ ||\n","`최적화(Optimization) <optimization_tutorial.html>`_ ||\n","`모델 저장하고 불러오기 <saveloadrun_tutorial.html>`_\n","\n","빠른 시작(Quickstart)\n","==========================================================================\n","이번 장에서는 기계 학습의 일반적인 작업들을 위한 API를 통해 실행됩니다. 더 자세히 알아보려면 각 장(section)의 링크를 참고하세요.\n","\n","데이터 작업하기\n","------------------------------------------------------------------------------------------\n","파이토치(PyTorch)에는 `데이터 작업을 위한 기본 요소 <https://pytorch.org/docs/stable/data.html>`_ 두가지인\n","``torch.utils.data.DataLoader`` 와 ``torch.utils.data.Dataset`` 가 있습니다.\n","``Dataset`` 은 샘플과 정답(label)을 저장하고, ``DataLoader`` 는 ``Dataset`` 을 순회 가능한 객체(iterable)로 감쌉니다.\n"]},{"cell_type":"code","metadata":{"id":"76eFfoQ1oAV0","executionInfo":{"status":"ok","timestamp":1637675420815,"user_tz":-540,"elapsed":2,"user":{"displayName":"빵식","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15051609577376359073"}}},"source":["import torch\n","from torch import nn\n","from torch.utils.data import DataLoader\n","from torchvision import datasets\n","from torchvision.transforms import ToTensor, Lambda, Compose\n","import matplotlib.pyplot as plt"],"execution_count":219,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bmOBp1nXoAV1"},"source":["PyTorch는 `TorchText <https://pytorch.org/text/stable/index.html>`_, `TorchVision <https://pytorch.org/vision/stable/index.html>`_ 및\n","`TorchAudio <https://pytorch.org/audio/stable/index.html>`_ 와 같이 도메인 특화 라이브러리를 데이터셋과 함께 제공하고 있습니다.\n","이 튜토리얼에서는 TorchVision 데이터셋을 사용하도록 하겠습니다.\n","\n","``torchvision.datasets`` 모듈은 CIFAR, COCO 등과 같은 다양한 실제 비전(vision) 데이터에 대한\n","``Dataset``\\ (`전체 목록은 여기 <https://pytorch.org/vision/stable/datasets.html>`_)\\ 을 포함하고 있습니다.\n","이 튜토리얼에서는 FasionMNIST 데이터셋을 사용합니다.\n","모든 TorchVision ``Dataset`` 은 샘플과 정답을 각각 변경하기 위한 ``transform`` 과 ``target_transform`` 의 두 인자를 포함합니다.\n","\n"]},{"cell_type":"code","metadata":{"id":"mIrRB1DUoAV1","executionInfo":{"status":"ok","timestamp":1637675420815,"user_tz":-540,"elapsed":1,"user":{"displayName":"빵식","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15051609577376359073"}}},"source":["# 공개 데이터셋에서 학습 데이터를 내려받습니다.\n","training_data = datasets.FashionMNIST(\n","    root=\"data\",\n","    train=True,\n","    download=True,\n","    transform=ToTensor(),\n",")\n","\n","# 공개 데이터셋에서 테스트 데이터를 내려받습니다.\n","test_data = datasets.FashionMNIST(\n","    root=\"data\",\n","    train=False,\n","    download=True,\n","    transform=ToTensor(),\n",")\n"],"execution_count":220,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LdX9wknd7cnm","executionInfo":{"status":"ok","timestamp":1637675421187,"user_tz":-540,"elapsed":3,"user":{"displayName":"빵식","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15051609577376359073"}},"outputId":"2c4237b1-e5db-4d73-d40a-a51eeb788c8d"},"source":["# 구글드라이브 연결\n","from google.colab import drive\n","drive.mount('/gdrive')"],"execution_count":221,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":265},"id":"Fd2jsc1D6DY4","executionInfo":{"status":"ok","timestamp":1637675422222,"user_tz":-540,"elapsed":1036,"user":{"displayName":"빵식","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15051609577376359073"}},"outputId":"f92f48ca-dc46-4f89-c4e6-a581936230b0"},"source":["# 데이터파일 불러오기\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","df = pd.read_csv('/gdrive/My Drive/3-2_machine_learning/image-10k.csv', header=None)\n","\n","X = df.iloc[:, 1:].values     # 데이터샘플\n","y = df.iloc[:, 0].values      # 타겟레이블\n","\n","plt.imshow(X[0].reshape(28,28), cmap='Greys', interpolation='nearest')\n","plt.show()\n","\n","x_train, x_test, y_train, y_test = train_test_split(\n","    X, y, test_size=0.5, random_state=1, stratify=y)\n","\n","x_train= torch.Tensor(x_train/255)\n","training_data = []\n","for i in range(y_train.shape[0]):\n","  training_data.append((x_train[i],y_train[i]))\n","\n","x_test= torch.Tensor(x_test/255)\n","test_data = []\n","for i in range(y_train.shape[0]):\n","  test_data.append((x_test[i],y_test[i]))"],"execution_count":222,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"swZNTpExoAV1"},"source":["``Dataset`` 을 ``DataLoader`` 의 인자로 전달합니다. 이는 데이터셋을 순회 가능한 객체(iterable)로 감싸고, 자동화된 배치(batch), 샘플링(sampling),\n","섞기(shuffle) 및 다중 프로세스로 데이터 불러오기(multiprocess data loading)를 지원합니다. 여기서는 배치 크기(batch size)를 64로 정의합니다.\n","즉, 데이터로더(dataloader) 객체의 각 요소는 64개의 특징(feature)과 정답(label)을 묶음(batch)으로 반환합니다.\n","\n"]},{"cell_type":"code","metadata":{"id":"I3voj38soAV2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637675422223,"user_tz":-540,"elapsed":5,"user":{"displayName":"빵식","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15051609577376359073"}},"outputId":"de77fd9f-0f09-4206-ba7f-65fc078f7397"},"source":["batch_size = 100\n","\n","# 데이터로더를 생성합니다.\n","train_dataloader = DataLoader(training_data, batch_size=batch_size)\n","test_dataloader = DataLoader(test_data, batch_size=batch_size)\n","\n","for X, y in test_dataloader:\n","    print(\"Shape of X [N, C, H, W]: \", X.shape)\n","    print(\"Shape of y: \", y.shape, y.dtype)\n","    break"],"execution_count":223,"outputs":[{"output_type":"stream","name":"stdout","text":["Shape of X [N, C, H, W]:  torch.Size([100, 784])\n","Shape of y:  torch.Size([100]) torch.int64\n"]}]},{"cell_type":"markdown","metadata":{"id":"YwEpR5Z2oAV2"},"source":["`PyTorch에서 데이터를 불러오는 방법 <data_tutorial.html>`_ 을 자세히 알아보세요.\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"UKRtQI2CoAV3"},"source":["------------------------------------------------------------------------------------------\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"5NLUMtstoAV3"},"source":["모델 만들기\n","------------------------------------------------------------------------------------------\n","PyTorch에서 신경망 모델은 `nn.Module <https://pytorch.org/docs/stable/generated/torch.nn.Module.html>`_ 을\n","상속받는 클래스(class)를 생성하여 정의합니다. ``__init__`` 함수에서 신경망의 계층(layer)들을 정의하고 ``forward`` 함수에서\n","신경망에 데이터를 어떻게 전달할지 지정합니다. 가능한 경우 GPU로 신경망을 이동시켜 연산을 가속(accelerate)합니다.\n","\n"]},{"cell_type":"code","metadata":{"id":"MpBz57vvoAV3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637675422223,"user_tz":-540,"elapsed":4,"user":{"displayName":"빵식","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15051609577376359073"}},"outputId":"4125bd93-39ce-49ec-82f0-48726e625ff6"},"source":["# 학습에 사용할 CPU나 GPU 장치를 얻습니다.\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(\"Using {} device\".format(device))\n","\n","# 모델을 정의합니다.\n","class NeuralNetwork(nn.Module):\n","    def __init__(self):\n","        super(NeuralNetwork, self).__init__()\n","        self.flatten = nn.Flatten()\n","        self.linear_relu_stack = nn.Sequential(\n","            nn.Linear(28*28, 512),\n","            torch.nn.BatchNorm1d(512),\n","            nn.ReLU(),\n","            nn.Linear(512, 512),\n","            torch.nn.BatchNorm1d(512),\n","            nn.ReLU(),\n","            nn.Linear(512, 10)\n","        )\n","\n","    def forward(self, x):\n","        x = self.flatten(x)\n","        logits = self.linear_relu_stack(x)\n","        return logits\n","\n","model = NeuralNetwork().to(device)\n","print(model)"],"execution_count":224,"outputs":[{"output_type":"stream","name":"stdout","text":["Using cpu device\n","NeuralNetwork(\n","  (flatten): Flatten(start_dim=1, end_dim=-1)\n","  (linear_relu_stack): Sequential(\n","    (0): Linear(in_features=784, out_features=512, bias=True)\n","    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","    (3): Linear(in_features=512, out_features=512, bias=True)\n","    (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (5): ReLU()\n","    (6): Linear(in_features=512, out_features=10, bias=True)\n","  )\n",")\n"]}]},{"cell_type":"markdown","metadata":{"id":"nRRigw2UoAV4"},"source":["`PyTorch에서 신경망을 정의하는 방법  <buildmodel_tutorial.html>`_ 을 자세히 알아보세요.\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"apAXntqWoAV4"},"source":["------------------------------------------------------------------------------------------\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"EwQ5BDlYoAV4"},"source":["모델 매개변수 최적화하기\n","------------------------------------------------------------------------------------------\n","모델을 학습하려면 `손실 함수(loss function) <https://pytorch.org/docs/stable/nn.html#loss-functions>`_ 와\n","`옵티마이저(optimizer) <https://pytorch.org/docs/stable/optim.html>`_ 가 필요합니다.\n","\n"]},{"cell_type":"code","metadata":{"id":"SE4PXtWzoAV4","executionInfo":{"status":"ok","timestamp":1637675422223,"user_tz":-540,"elapsed":3,"user":{"displayName":"빵식","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15051609577376359073"}}},"source":["loss_fn = nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(model.parameters(), lr=5e-3,weight_decay=1e-3)\n","#optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)"],"execution_count":225,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"N_Sustq9oAV4"},"source":["각 학습 단계(training loop)에서 모델은 (배치(batch)로 제공되는) 학습 데이터셋에 대한 예측을 수행하고,\n","예측 오류를 역전파하여 모델의 매개변수를 조정합니다.\n","\n"]},{"cell_type":"code","metadata":{"id":"JvRt04IXoAV5","executionInfo":{"status":"ok","timestamp":1637675422224,"user_tz":-540,"elapsed":4,"user":{"displayName":"빵식","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15051609577376359073"}}},"source":["def train(dataloader, model, loss_fn, optimizer):\n","    size = len(dataloader.dataset)\n","    for batch, (X, y) in enumerate(dataloader):\n","        X, y = X.to(device), y.to(device)\n","\n","        # 예측 오류 계산\n","        pred = model(X)\n","        loss = loss_fn(pred, y)\n","\n","        # 역전파\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        if batch % 10 == 0:\n","            loss, current = loss.item(), batch * len(X)\n","            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"],"execution_count":226,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Nuh3dv6zoAV5"},"source":["모델이 학습하고 있는지를 확인하기 위해 테스트 데이터셋으로 모델의 성능을 확인합니다.\n","\n"]},{"cell_type":"code","metadata":{"id":"ps2iMMXUoAV5","executionInfo":{"status":"ok","timestamp":1637675422225,"user_tz":-540,"elapsed":5,"user":{"displayName":"빵식","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15051609577376359073"}}},"source":["def test(dataloader, model, loss_fn):\n","    size = len(dataloader.dataset)\n","    num_batches = len(dataloader)\n","    model.eval()\n","    test_loss, correct = 0, 0\n","    with torch.no_grad():\n","        for X, y in dataloader:\n","            X, y = X.to(device), y.to(device)\n","            pred = model(X)\n","            test_loss += loss_fn(pred, y).item()\n","            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n","    test_loss /= num_batches\n","    correct /= size\n","    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"],"execution_count":227,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DzpzE_whoAV5"},"source":["학습 단계는 여러번의 반복 단계 (*에폭(epochs)*) 를 거쳐서 수행됩니다. 각 에폭에서는 모델은 더 나은 예측을 하기 위해  매개변수를 학습합니다.\n","각 에폭마다 모델의 정확도(accuracy)와 손실(loss)을 출력합니다; 에폭마다 정확도가 증가하고 손실이 감소하는 것을 보려고 합니다.\n","\n"]},{"cell_type":"code","metadata":{"id":"3Hru7KBcoAV5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637675455964,"user_tz":-540,"elapsed":33744,"user":{"displayName":"빵식","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15051609577376359073"}},"outputId":"96199272-1a9b-4649-dd4b-b34760164042"},"source":["epochs = 50\n","for t in range(epochs):\n","    print(f\"Epoch {t+1}\\n-------------------------------\")\n","    train(train_dataloader, model, loss_fn, optimizer)\n","    test(test_dataloader, model, loss_fn)\n","print(\"Done!\")"],"execution_count":228,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1\n","-------------------------------\n","loss: 2.297120  [    0/ 5000]\n","loss: 1.677056  [ 1000/ 5000]\n","loss: 1.339461  [ 2000/ 5000]\n","loss: 1.275658  [ 3000/ 5000]\n","loss: 1.116088  [ 4000/ 5000]\n","Test Error: \n"," Accuracy: 72.7%, Avg loss: 1.054461 \n","\n","Epoch 2\n","-------------------------------\n","loss: 1.020431  [    0/ 5000]\n","loss: 0.854723  [ 1000/ 5000]\n","loss: 0.755984  [ 2000/ 5000]\n","loss: 0.799861  [ 3000/ 5000]\n","loss: 0.815553  [ 4000/ 5000]\n","Test Error: \n"," Accuracy: 76.9%, Avg loss: 0.681412 \n","\n","Epoch 3\n","-------------------------------\n","loss: 0.569144  [    0/ 5000]\n","loss: 0.625784  [ 1000/ 5000]\n","loss: 0.630379  [ 2000/ 5000]\n","loss: 0.661013  [ 3000/ 5000]\n","loss: 0.719049  [ 4000/ 5000]\n","Test Error: \n"," Accuracy: 78.6%, Avg loss: 0.609656 \n","\n","Epoch 4\n","-------------------------------\n","loss: 0.473495  [    0/ 5000]\n","loss: 0.553729  [ 1000/ 5000]\n","loss: 0.577004  [ 2000/ 5000]\n","loss: 0.591518  [ 3000/ 5000]\n","loss: 0.668918  [ 4000/ 5000]\n","Test Error: \n"," Accuracy: 79.6%, Avg loss: 0.570068 \n","\n","Epoch 5\n","-------------------------------\n","loss: 0.419012  [    0/ 5000]\n","loss: 0.513735  [ 1000/ 5000]\n","loss: 0.539305  [ 2000/ 5000]\n","loss: 0.543947  [ 3000/ 5000]\n","loss: 0.635808  [ 4000/ 5000]\n","Test Error: \n"," Accuracy: 80.7%, Avg loss: 0.543598 \n","\n","Epoch 6\n","-------------------------------\n","loss: 0.381399  [    0/ 5000]\n","loss: 0.487629  [ 1000/ 5000]\n","loss: 0.510125  [ 2000/ 5000]\n","loss: 0.504280  [ 3000/ 5000]\n","loss: 0.612603  [ 4000/ 5000]\n","Test Error: \n"," Accuracy: 81.4%, Avg loss: 0.523914 \n","\n","Epoch 7\n","-------------------------------\n","loss: 0.353949  [    0/ 5000]\n","loss: 0.469184  [ 1000/ 5000]\n","loss: 0.485242  [ 2000/ 5000]\n","loss: 0.472428  [ 3000/ 5000]\n","loss: 0.592602  [ 4000/ 5000]\n","Test Error: \n"," Accuracy: 81.9%, Avg loss: 0.508971 \n","\n","Epoch 8\n","-------------------------------\n","loss: 0.333574  [    0/ 5000]\n","loss: 0.449919  [ 1000/ 5000]\n","loss: 0.463847  [ 2000/ 5000]\n","loss: 0.446113  [ 3000/ 5000]\n","loss: 0.575293  [ 4000/ 5000]\n","Test Error: \n"," Accuracy: 82.3%, Avg loss: 0.496782 \n","\n","Epoch 9\n","-------------------------------\n","loss: 0.316378  [    0/ 5000]\n","loss: 0.432294  [ 1000/ 5000]\n","loss: 0.443549  [ 2000/ 5000]\n","loss: 0.423876  [ 3000/ 5000]\n","loss: 0.561200  [ 4000/ 5000]\n","Test Error: \n"," Accuracy: 82.8%, Avg loss: 0.487012 \n","\n","Epoch 10\n","-------------------------------\n","loss: 0.302747  [    0/ 5000]\n","loss: 0.417409  [ 1000/ 5000]\n","loss: 0.427494  [ 2000/ 5000]\n","loss: 0.404891  [ 3000/ 5000]\n","loss: 0.547965  [ 4000/ 5000]\n","Test Error: \n"," Accuracy: 83.1%, Avg loss: 0.478652 \n","\n","Epoch 11\n","-------------------------------\n","loss: 0.290424  [    0/ 5000]\n","loss: 0.404316  [ 1000/ 5000]\n","loss: 0.412143  [ 2000/ 5000]\n","loss: 0.387648  [ 3000/ 5000]\n","loss: 0.535062  [ 4000/ 5000]\n","Test Error: \n"," Accuracy: 83.3%, Avg loss: 0.472408 \n","\n","Epoch 12\n","-------------------------------\n","loss: 0.280529  [    0/ 5000]\n","loss: 0.390886  [ 1000/ 5000]\n","loss: 0.396752  [ 2000/ 5000]\n","loss: 0.371055  [ 3000/ 5000]\n","loss: 0.521665  [ 4000/ 5000]\n","Test Error: \n"," Accuracy: 83.4%, Avg loss: 0.466522 \n","\n","Epoch 13\n","-------------------------------\n","loss: 0.271957  [    0/ 5000]\n","loss: 0.378257  [ 1000/ 5000]\n","loss: 0.384704  [ 2000/ 5000]\n","loss: 0.357529  [ 3000/ 5000]\n","loss: 0.509819  [ 4000/ 5000]\n","Test Error: \n"," Accuracy: 83.7%, Avg loss: 0.461649 \n","\n","Epoch 14\n","-------------------------------\n","loss: 0.264882  [    0/ 5000]\n","loss: 0.368269  [ 1000/ 5000]\n","loss: 0.372578  [ 2000/ 5000]\n","loss: 0.344470  [ 3000/ 5000]\n","loss: 0.501933  [ 4000/ 5000]\n","Test Error: \n"," Accuracy: 83.8%, Avg loss: 0.457551 \n","\n","Epoch 15\n","-------------------------------\n","loss: 0.257562  [    0/ 5000]\n","loss: 0.358937  [ 1000/ 5000]\n","loss: 0.360603  [ 2000/ 5000]\n","loss: 0.333369  [ 3000/ 5000]\n","loss: 0.490683  [ 4000/ 5000]\n","Test Error: \n"," Accuracy: 83.9%, Avg loss: 0.454072 \n","\n","Epoch 16\n","-------------------------------\n","loss: 0.251530  [    0/ 5000]\n","loss: 0.351094  [ 1000/ 5000]\n","loss: 0.350219  [ 2000/ 5000]\n","loss: 0.321886  [ 3000/ 5000]\n","loss: 0.478569  [ 4000/ 5000]\n","Test Error: \n"," Accuracy: 84.0%, Avg loss: 0.451069 \n","\n","Epoch 17\n","-------------------------------\n","loss: 0.246366  [    0/ 5000]\n","loss: 0.341248  [ 1000/ 5000]\n","loss: 0.338996  [ 2000/ 5000]\n","loss: 0.311973  [ 3000/ 5000]\n","loss: 0.466997  [ 4000/ 5000]\n","Test Error: \n"," Accuracy: 84.0%, Avg loss: 0.448514 \n","\n","Epoch 18\n","-------------------------------\n","loss: 0.239669  [    0/ 5000]\n","loss: 0.331314  [ 1000/ 5000]\n","loss: 0.329033  [ 2000/ 5000]\n","loss: 0.302495  [ 3000/ 5000]\n","loss: 0.456211  [ 4000/ 5000]\n","Test Error: \n"," Accuracy: 84.2%, Avg loss: 0.445618 \n","\n","Epoch 19\n","-------------------------------\n","loss: 0.234986  [    0/ 5000]\n","loss: 0.324380  [ 1000/ 5000]\n","loss: 0.319934  [ 2000/ 5000]\n","loss: 0.293696  [ 3000/ 5000]\n","loss: 0.446668  [ 4000/ 5000]\n","Test Error: \n"," Accuracy: 84.4%, Avg loss: 0.443418 \n","\n","Epoch 20\n","-------------------------------\n","loss: 0.229495  [    0/ 5000]\n","loss: 0.316556  [ 1000/ 5000]\n","loss: 0.311461  [ 2000/ 5000]\n","loss: 0.284934  [ 3000/ 5000]\n","loss: 0.435160  [ 4000/ 5000]\n","Test Error: \n"," Accuracy: 84.5%, Avg loss: 0.441730 \n","\n","Epoch 21\n","-------------------------------\n","loss: 0.225877  [    0/ 5000]\n","loss: 0.309872  [ 1000/ 5000]\n","loss: 0.303358  [ 2000/ 5000]\n","loss: 0.276984  [ 3000/ 5000]\n","loss: 0.425341  [ 4000/ 5000]\n","Test Error: \n"," Accuracy: 84.6%, Avg loss: 0.439892 \n","\n","Epoch 22\n","-------------------------------\n","loss: 0.221876  [    0/ 5000]\n","loss: 0.301095  [ 1000/ 5000]\n","loss: 0.295939  [ 2000/ 5000]\n","loss: 0.269739  [ 3000/ 5000]\n","loss: 0.416631  [ 4000/ 5000]\n","Test Error: \n"," Accuracy: 84.8%, Avg loss: 0.438922 \n","\n","Epoch 23\n","-------------------------------\n","loss: 0.219205  [    0/ 5000]\n","loss: 0.297518  [ 1000/ 5000]\n","loss: 0.288522  [ 2000/ 5000]\n","loss: 0.263493  [ 3000/ 5000]\n","loss: 0.406818  [ 4000/ 5000]\n","Test Error: \n"," Accuracy: 84.8%, Avg loss: 0.437637 \n","\n","Epoch 24\n","-------------------------------\n","loss: 0.215440  [    0/ 5000]\n","loss: 0.287482  [ 1000/ 5000]\n","loss: 0.281108  [ 2000/ 5000]\n","loss: 0.256316  [ 3000/ 5000]\n","loss: 0.398957  [ 4000/ 5000]\n","Test Error: \n"," Accuracy: 84.9%, Avg loss: 0.436516 \n","\n","Epoch 25\n","-------------------------------\n","loss: 0.212022  [    0/ 5000]\n","loss: 0.283137  [ 1000/ 5000]\n","loss: 0.273873  [ 2000/ 5000]\n","loss: 0.251079  [ 3000/ 5000]\n","loss: 0.389429  [ 4000/ 5000]\n","Test Error: \n"," Accuracy: 85.0%, Avg loss: 0.435815 \n","\n","Epoch 26\n","-------------------------------\n","loss: 0.208841  [    0/ 5000]\n","loss: 0.280135  [ 1000/ 5000]\n","loss: 0.267862  [ 2000/ 5000]\n","loss: 0.244743  [ 3000/ 5000]\n","loss: 0.380260  [ 4000/ 5000]\n","Test Error: \n"," Accuracy: 85.0%, Avg loss: 0.435539 \n","\n","Epoch 27\n","-------------------------------\n","loss: 0.206766  [    0/ 5000]\n","loss: 0.275686  [ 1000/ 5000]\n","loss: 0.261671  [ 2000/ 5000]\n","loss: 0.239184  [ 3000/ 5000]\n","loss: 0.373182  [ 4000/ 5000]\n","Test Error: \n"," Accuracy: 85.0%, Avg loss: 0.434883 \n","\n","Epoch 28\n","-------------------------------\n","loss: 0.203320  [    0/ 5000]\n","loss: 0.263647  [ 1000/ 5000]\n","loss: 0.254891  [ 2000/ 5000]\n","loss: 0.233903  [ 3000/ 5000]\n","loss: 0.364552  [ 4000/ 5000]\n","Test Error: \n"," Accuracy: 84.9%, Avg loss: 0.434235 \n","\n","Epoch 29\n","-------------------------------\n","loss: 0.200205  [    0/ 5000]\n","loss: 0.259633  [ 1000/ 5000]\n","loss: 0.249153  [ 2000/ 5000]\n","loss: 0.228605  [ 3000/ 5000]\n","loss: 0.355343  [ 4000/ 5000]\n","Test Error: \n"," Accuracy: 85.0%, Avg loss: 0.433931 \n","\n","Epoch 30\n","-------------------------------\n","loss: 0.197756  [    0/ 5000]\n","loss: 0.253439  [ 1000/ 5000]\n","loss: 0.243429  [ 2000/ 5000]\n","loss: 0.224427  [ 3000/ 5000]\n","loss: 0.348047  [ 4000/ 5000]\n","Test Error: \n"," Accuracy: 85.0%, Avg loss: 0.433201 \n","\n","Epoch 31\n","-------------------------------\n","loss: 0.193864  [    0/ 5000]\n","loss: 0.240213  [ 1000/ 5000]\n","loss: 0.237546  [ 2000/ 5000]\n","loss: 0.219272  [ 3000/ 5000]\n","loss: 0.340920  [ 4000/ 5000]\n","Test Error: \n"," Accuracy: 85.1%, Avg loss: 0.433375 \n","\n","Epoch 32\n","-------------------------------\n","loss: 0.191620  [    0/ 5000]\n","loss: 0.249061  [ 1000/ 5000]\n","loss: 0.232857  [ 2000/ 5000]\n","loss: 0.215420  [ 3000/ 5000]\n","loss: 0.330353  [ 4000/ 5000]\n","Test Error: \n"," Accuracy: 85.1%, Avg loss: 0.433097 \n","\n","Epoch 33\n","-------------------------------\n","loss: 0.188576  [    0/ 5000]\n","loss: 0.231481  [ 1000/ 5000]\n","loss: 0.226062  [ 2000/ 5000]\n","loss: 0.210951  [ 3000/ 5000]\n","loss: 0.323719  [ 4000/ 5000]\n","Test Error: \n"," Accuracy: 85.2%, Avg loss: 0.433653 \n","\n","Epoch 34\n","-------------------------------\n","loss: 0.186814  [    0/ 5000]\n","loss: 0.247457  [ 1000/ 5000]\n","loss: 0.222691  [ 2000/ 5000]\n","loss: 0.206964  [ 3000/ 5000]\n","loss: 0.314570  [ 4000/ 5000]\n","Test Error: \n"," Accuracy: 85.2%, Avg loss: 0.433347 \n","\n","Epoch 35\n","-------------------------------\n","loss: 0.182114  [    0/ 5000]\n","loss: 0.236304  [ 1000/ 5000]\n","loss: 0.217607  [ 2000/ 5000]\n","loss: 0.202591  [ 3000/ 5000]\n","loss: 0.307856  [ 4000/ 5000]\n","Test Error: \n"," Accuracy: 85.3%, Avg loss: 0.434196 \n","\n","Epoch 36\n","-------------------------------\n","loss: 0.180940  [    0/ 5000]\n","loss: 0.230012  [ 1000/ 5000]\n","loss: 0.212111  [ 2000/ 5000]\n","loss: 0.199108  [ 3000/ 5000]\n","loss: 0.301214  [ 4000/ 5000]\n","Test Error: \n"," Accuracy: 85.2%, Avg loss: 0.434807 \n","\n","Epoch 37\n","-------------------------------\n","loss: 0.177921  [    0/ 5000]\n","loss: 0.232138  [ 1000/ 5000]\n","loss: 0.207075  [ 2000/ 5000]\n","loss: 0.195328  [ 3000/ 5000]\n","loss: 0.292097  [ 4000/ 5000]\n","Test Error: \n"," Accuracy: 85.3%, Avg loss: 0.435268 \n","\n","Epoch 38\n","-------------------------------\n","loss: 0.175375  [    0/ 5000]\n","loss: 0.228125  [ 1000/ 5000]\n","loss: 0.203365  [ 2000/ 5000]\n","loss: 0.191528  [ 3000/ 5000]\n","loss: 0.284886  [ 4000/ 5000]\n","Test Error: \n"," Accuracy: 85.2%, Avg loss: 0.435662 \n","\n","Epoch 39\n","-------------------------------\n","loss: 0.172560  [    0/ 5000]\n","loss: 0.208989  [ 1000/ 5000]\n","loss: 0.197510  [ 2000/ 5000]\n","loss: 0.188187  [ 3000/ 5000]\n","loss: 0.277384  [ 4000/ 5000]\n","Test Error: \n"," Accuracy: 85.2%, Avg loss: 0.436065 \n","\n","Epoch 40\n","-------------------------------\n","loss: 0.170378  [    0/ 5000]\n","loss: 0.229451  [ 1000/ 5000]\n","loss: 0.193549  [ 2000/ 5000]\n","loss: 0.184917  [ 3000/ 5000]\n","loss: 0.270112  [ 4000/ 5000]\n","Test Error: \n"," Accuracy: 85.2%, Avg loss: 0.437247 \n","\n","Epoch 41\n","-------------------------------\n","loss: 0.167800  [    0/ 5000]\n","loss: 0.190701  [ 1000/ 5000]\n","loss: 0.190238  [ 2000/ 5000]\n","loss: 0.181858  [ 3000/ 5000]\n","loss: 0.264294  [ 4000/ 5000]\n","Test Error: \n"," Accuracy: 85.1%, Avg loss: 0.437435 \n","\n","Epoch 42\n","-------------------------------\n","loss: 0.165670  [    0/ 5000]\n","loss: 0.220923  [ 1000/ 5000]\n","loss: 0.184336  [ 2000/ 5000]\n","loss: 0.178942  [ 3000/ 5000]\n","loss: 0.255564  [ 4000/ 5000]\n","Test Error: \n"," Accuracy: 85.2%, Avg loss: 0.437998 \n","\n","Epoch 43\n","-------------------------------\n","loss: 0.162412  [    0/ 5000]\n","loss: 0.171190  [ 1000/ 5000]\n","loss: 0.183906  [ 2000/ 5000]\n","loss: 0.174931  [ 3000/ 5000]\n","loss: 0.250205  [ 4000/ 5000]\n","Test Error: \n"," Accuracy: 85.1%, Avg loss: 0.438780 \n","\n","Epoch 44\n","-------------------------------\n","loss: 0.161443  [    0/ 5000]\n","loss: 0.238442  [ 1000/ 5000]\n","loss: 0.178288  [ 2000/ 5000]\n","loss: 0.173621  [ 3000/ 5000]\n","loss: 0.239824  [ 4000/ 5000]\n","Test Error: \n"," Accuracy: 85.1%, Avg loss: 0.439628 \n","\n","Epoch 45\n","-------------------------------\n","loss: 0.157695  [    0/ 5000]\n","loss: 0.163145  [ 1000/ 5000]\n","loss: 0.179382  [ 2000/ 5000]\n","loss: 0.169862  [ 3000/ 5000]\n","loss: 0.238089  [ 4000/ 5000]\n","Test Error: \n"," Accuracy: 85.1%, Avg loss: 0.439340 \n","\n","Epoch 46\n","-------------------------------\n","loss: 0.156276  [    0/ 5000]\n","loss: 0.166802  [ 1000/ 5000]\n","loss: 0.174209  [ 2000/ 5000]\n","loss: 0.167955  [ 3000/ 5000]\n","loss: 0.231865  [ 4000/ 5000]\n","Test Error: \n"," Accuracy: 85.0%, Avg loss: 0.440654 \n","\n","Epoch 47\n","-------------------------------\n","loss: 0.154991  [    0/ 5000]\n","loss: 0.164920  [ 1000/ 5000]\n","loss: 0.165195  [ 2000/ 5000]\n","loss: 0.168407  [ 3000/ 5000]\n","loss: 0.220507  [ 4000/ 5000]\n","Test Error: \n"," Accuracy: 85.0%, Avg loss: 0.440804 \n","\n","Epoch 48\n","-------------------------------\n","loss: 0.150679  [    0/ 5000]\n","loss: 0.198009  [ 1000/ 5000]\n","loss: 0.171162  [ 2000/ 5000]\n","loss: 0.162166  [ 3000/ 5000]\n","loss: 0.217023  [ 4000/ 5000]\n","Test Error: \n"," Accuracy: 85.0%, Avg loss: 0.441474 \n","\n","Epoch 49\n","-------------------------------\n","loss: 0.148531  [    0/ 5000]\n","loss: 0.151026  [ 1000/ 5000]\n","loss: 0.162880  [ 2000/ 5000]\n","loss: 0.159890  [ 3000/ 5000]\n","loss: 0.212134  [ 4000/ 5000]\n","Test Error: \n"," Accuracy: 85.0%, Avg loss: 0.442266 \n","\n","Epoch 50\n","-------------------------------\n","loss: 0.146846  [    0/ 5000]\n","loss: 0.140698  [ 1000/ 5000]\n","loss: 0.157475  [ 2000/ 5000]\n","loss: 0.159370  [ 3000/ 5000]\n","loss: 0.205275  [ 4000/ 5000]\n","Test Error: \n"," Accuracy: 85.0%, Avg loss: 0.444035 \n","\n","Done!\n"]}]},{"cell_type":"markdown","metadata":{"id":"OskGDB6yoAV6"},"source":["`모델을 학습하는 방법 <optimization_tutorial.html>`_ 을 자세히 알아보세요.\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"7J3lBhPhoAV6"},"source":["------------------------------------------------------------------------------------------\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"DMNfpAqAoAV6"},"source":["모델 저장하기\n","------------------------------------------------------------------------------------------\n","모델을 저장하는 일반적인 방법은 (모델의 매개변수들을 포함하여) 내부 상태 사전(internal state dictionary)을\n","직렬화(serialize)하는 것입니다.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"iH1VbQmhoAV6"},"source":["모델 불러오기\n","------------------------------------------------------------------------------------------\n","\n","모델을 불러오는 과정에는 모델 구조를 다시 만들고 상태 사전을 모델에 불러오는 과정이 포함됩니다.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Vic4lwLfoAV6"},"source":["이제 이 모델을 사용해서 예측을 할 수 있습니다.\n","\n"]},{"cell_type":"code","metadata":{"id":"9mB1YaLtoAV6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637675455965,"user_tz":-540,"elapsed":12,"user":{"displayName":"빵식","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15051609577376359073"}},"outputId":"79d246bf-663a-4a45-9e7d-f5eae64d1b74"},"source":["classes = [\n","    \"T-shirt/top\",\n","    \"Trouser\",\n","    \"Pullover\",\n","    \"Dress\",\n","    \"Coat\",\n","    \"Sandal\",\n","    \"Shirt\",\n","    \"Sneaker\",\n","    \"Bag\",\n","    \"Ankle boot\",\n","]\n","\n","model.eval()\n","x, y = test_data[0][0], test_data[0][1]\n","with torch.no_grad():\n","    pred = model(x.reshape([1,-1,28]))\n","    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n","    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"],"execution_count":229,"outputs":[{"output_type":"stream","name":"stdout","text":["Predicted: \"Pullover\", Actual: \"Pullover\"\n"]}]},{"cell_type":"markdown","metadata":{"id":"L2jYKMg4oAV7"},"source":["`모델을 저장하고 불러오는 방법 <saveloadrun_tutorial.html>`_ 을 자세히 알아보세요.\n","\n","\n"]}]}